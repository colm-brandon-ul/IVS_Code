import nltk

class Tokenization:
    def __init__(self, sentence_map):
        self.sentence_map = sentence_map


